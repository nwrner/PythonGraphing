import matplotlib.pyplot as plt
x = [1,2,3]
y = [5,7,4]

x2= [1,2,3]
y2= [10, 14,12]
plt.plot(x,y, label="firstline")
plt.plot(x2,y2, label="secondline")
plt.xlabel('Plot Number')
plt.ylabel('Important Var')
plt.title('Interesting Graph')
plt.legend()
plt.show()


import matplotlib.pyplot as plt
population_ages = [22,33,44,55,66,77,88,99,101,122,62,4,1,45,77,33,11,33,54]

#ids = [x for x in range(len(population_ages))]
bins = [0,10,20,30,40,50,60,70,80,90,100,110,120]
plt.hist(population_ages, bins, histtype='bar', rwidth=0.8)



'''
x = [2,4,6,8,10]
y = [6,7,8,2,4]

x2 = [1,3,5,7,9]
y2 = [7,8,2,4,2]

plt.bar(x,y, label="Bars1", color="Blue")
plt.bar(x2,y2, label="Bars2", color="Green")
'''
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Interesting Graph')
plt.legend()
plt.show()


days = [1,2,3,4,5]
sleeping = [7,8,6,11,7]
eating = [2,3,4,3,2]
working = [7,8,7,2,2]
playing = [8,5,7,8,13]


plt.stackplot(days, sleeping,eating,working,playing, labels=['sleeping','eating','working','playing'], colors=['m', 'c', 'r' , 'k'])

//plotting ten million points < 10 seconds
while num!=10000000:
        population_ages.append(randint(0,130))
        num+=1 
        
        
        
        
 #############PIE CHART################
 #!/usr/bin/python
import matplotlib.pyplot as plt
from random import *
days = [1,2,3,4,5]
sleeping = [7,8,6,11,7]
eating = [2,3,4,3,2]
working = [7,8,7,2,2]
playing = [8,5,7,8,13]

slices = [7,2,2,13]
activities = ['sleeping','eating','working','playing']
cols = ['c','m','r','b']
plt.pie(slices, labels=activities, colors=cols, explode=(0,0.1,0.5,0), autopct='%1.1f%%')

#plt.xlabel('X')
#plt.ylabel('Y')
plt.title('Interesting Graph')
#plt.legend()
plt.show()
plt.show()

############ Pulling from File #############
import matplotlib.pyplot as plt
from random import *
import numpy as np
import csv
#New Way 

out=open('example.csv', 'w')
num=0
data=50
while num!=100000:
        out.write(str(num) + ":" + str(randint(0,1000000)) + '\n')
        num+=1


if num==100000:
        out.close()

x, y = np.loadtxt('example.csv', delimiter=':', unpack=True)


############# PANDAS ################
import pandas as pd
import datetime
f
import pandas_datareader as web
import matplotlib.pyplot as plt
from matplotlib import style
style.use('ggplot')

web_stats = {'Day':[1,2,3,4,5,6],
             'Visitors':[43,53,34,45,64,34],
             'Bounce Rate':[65,72,62,64,54,66],
             'Buyers':[11,22,33,44,55,66]
             }

df = pd.DataFrame(web_stats)
df.set_index('Day', inplace=True)
print(df.Buyers)


######### PANDAS ITERATION 1 #############
import pandas as pd
import datetime
import numpy as np
import pandas_datareader as web
import matplotlib.pyplot as plt
from matplotlib import style

style.use('ggplot')

web_stats = {'Day':[1,2,3,4,5,6],
             'Visitors':[43,53,34,45,64,34],
             'Bounce Rate':[65,72,62,64,54,66],
             'Buyers':[11,22,33,44,55,66]
             }

df = pd.DataFrame(web_stats)
df.set_index('Day', inplace=True)
print(df)













#Information Storehouse

#df.set_index('1', inplace=True)
#print(df.Buyers)
#print(df[['Bounce Rate','Buyers']])
#visitors=df.Visitors.tolist()
#print(np.array(df[['Bounce Rate','Visitors']]))


#Progressionist Pit
'''
file=input("Access what file?: ")
data_di={}
data=open(file,'r')

for line in data:
    (key,val) = line.split()
    data_di[int(key)]=val

print(data_di)
'''

########### PANDAS ITERATION 2 ############
#Read the CSV file into Python and assign that to a data set. 
df = pd.read_csv('C:\\Users\\Nick\\Desktop\\Python\\FMAC-HPI_DENCO.csv')

#Gets rid of the counter next to each line but has the side effect
#of swapping the columns if desired by swapping the title of two rows with eachother. ¯\_(ツ)_/¯
df.set_index('Date', inplace=True)

#Take the data from that opened file, apply any changes made there ^ and put into a new file called newcsv2.csv. 
df.to_csv('C:\\Users\\Nick\\Desktop\\Python\\newcsv2.csv')

#Open that file ^ and assign it an index of 0.
df=pd.read_csv('C:\\Users\\Nick\\Desktop\\Python\\newcsv2.csv', index_col=0)
#Rename the column with the new index to 'Denver_HPI'. 
df.columns = ['Denver_HPI']

#Take the data from that opened file, apply any changes made there ^ and put into a new file called newcsv3.csv.
df.to_csv('C:\\Users\\Nick\\Desktop\\Python\\header.csv')
#Remove any headers and just give the data.
df.to_csv('C:\\Users\\Nick\\Desktop\\Python\\header_no.csv', header=False)
#Add headers to a file that doesn't have any.
df = pd.read_csv('C:\\Users\\Nick\\Desktop\\Python\\header_no.csv', names=['Date','Denver_HPI'])
#Renaming column name 
df.rename(columns={'Denver_HPI':'77075_HPI'}, inplace=True)
df.to_csv("C:\\Users\\Nick\\Desktop\\Python\\header_change.csv")
#Exporting data to HTML
df.to_html('C:\\Users\\Nick\\Desktop\\Python\\example.html')

import pandas as pd
import quandl
api_key='RZxXTz8kkfTXooDi3vzx'
df=quandl.get('FMAC/HPI_AK', auth_token=api_key)
df2=quandl.get('FMAC/HPI_HI', auth_token=api_key)
#print("======== ALASKA ========") 
#print(df.tail())
#print('========= DENVER ==========')
#print(df2.tail())

fiddy_states=["AK","AL","AR","AZ","CA","CO","CT","DC","DE","FL","GA","GU","HI","IA","ID", "IL","IN","KS","KY","LA","MA","MD","ME","MH","MI","MN","MO","MS","MT","NC","ND","NE","NH","NJ","NM","NV","NY", "OH","OK","OR","PA","PR","PW","RI","SC","SD","TN","TX","UT","VA","VI","VT","WA","WI","WV","WY"]
for x in fiddy_states:
    print("FMAC/HPI_"+str(x))
    df2=quandl.get("FMAC/HPI_"+str(x))
    
 ################### Concatentation(sp?) and Appending ##############
 #Define a bunch of data
df1 = pd.DataFrame({'HPI':[80,85,88,85],
                    'Int_rate':[2, 3, 2, 2],
                    'US_GDP_Thousands':[50, 55, 65, 55]},
                   index = [2001, 2002, 2003, 2004])

df2 = pd.DataFrame({'HPI':[80,85,88,85],
                    'Int_rate':[2, 3, 2, 2],
                    'US_GDP_Thousands':[50, 55, 65, 55]},
                   index = [2005, 2006, 2007, 2008])

df3 = pd.DataFrame({'HPI':[80,85,88,85],
                    'Int_rate':[2, 3, 2, 2],
                    'Low_tier_HPI':[50, 52, 50, 53]},
                   index = [2001, 2002, 2003, 2004])
#Combine the first and second dataframe
concat=pd.concat([df1,df2])

#Define a panda series
s = pd.Series([80,2,50], index= ['HPI','Int_rate','US_GDP_Thousands'])

#add that to the combines series
df4=df1.append(s, ignore_index=True)

print(df4)

##########Merging and Joining######################
import pandas as pd

#Merging multiple data frames 
df1 = pd.DataFrame({'HPI':[80,85,88,85],
                    'Int_rate':[2, 3, 2, 2],
                    'US_GDP_Thousands':[50, 55, 65, 55]},
                   index = [2001, 2002, 2003, 2004])

df2 = pd.DataFrame({'HPI':[80,85,88,85],
                    'Int_rate':[2, 3, 2, 2],
                    'US_GDP_Thousands':[50, 55, 65, 55]},
                   index = [2005, 2006, 2007, 2008])

df3 = pd.DataFrame({'HPI':[80,85,88,85],
                    'Unemployment':[7, 8, 9, 6],
                    'Low_tier_HPI':[50, 52, 50, 53]},
                   index = [2001, 2002, 2003, 2004])
##print(pd.merge(df1,df2, on=["HPI", "Int_rate"]))

df1.set_index('HPI', inplace=True)
df3.set_index('HPI', inplace=True)

joined=df1.join(df3)
print(joined)

######### Merging Continued #################
#Merging multiple data frames 
df1 = pd.DataFrame({'Year':[2001,2002,2003,2004],
                    'Int_rate':[2, 3, 2, 2],
                    'US_GDP_Thousands':[50, 55, 65, 55]})


df3 = pd.DataFrame({'Year':[2001,2003,2004,2005],
                    'Unemployment':[7, 8, 9, 6],
                    'Low_tier_HPI':[50, 52, 50, 53]})
##print(pd.merge(df1,df2, on=["HPI", "Int_rate"]))

merged = pd.merge(df1, df3, on = "Year", how="outer" )
merged.set_index('Year', inplace=True)
print(merged)

#############Pickling and Intermediate Importation###########  
import quandl
import pandas as pd
import pickle 
api_key='RZxXTz8kkfTXooDi3vzx'
#fiddy_states=["AK","AL","AR","AZ","CA","CO","CT","DC","DE","FL","GA","GU","HI","IA","ID", "IL","IN","KS","KY","LA","MA","MD","ME","MH","MI","MN","MO","MS","MT","NC","ND","NE","NH","NJ","NM","NV","NY", "OH","OK","OR","PA","PR","PW","RI","SC","SD","TN","TX","UT","VA","VI","VT","WA","WI","WV","WY"]


def state_list():
    fiddy_states = pd.read_html('https://simple.wikipedia.org/wiki/List_of_U.S._states')
    return fiddy_states[0][0][1:]

def grab_initial_state_data():
    states=state_list()
    main_df=pd.DataFrame()

    for abbv in states:
        #print(abbv)
        query= "FMAC/HPI_"+str(abbv)
        df= quandl.get(query, authtoken=api_key)
        df.columns = [str(abbv)]
        if main_df.empty:
            main_df=df
        else:
            main_df=main_df.join(df)

    #print(main_df)    
    #pickle_out = open ("fiddy_states.pickle", "wb")
    #pickle.dump(main_df, pickle_out)
    #pickle_out.close()
    main_df.to_pickle('main.pickle')
    main_data=pd.read_pickle('C:\\Users\\Nick\\Desktop\\Python\\main.pickle')
    print(main_data)
    
        
grab_initial_state_data()
#pickle_in = open ("fiddy_states.pickle", "rb")
#HPI_data = pickle.load(pickle_in)
#print(HPI_data)

#print(main_data)
#print(main_df.head())
#main_df.to_csv('C:\\Users\\Nick\\Desktop\Python\stateout.csv')
